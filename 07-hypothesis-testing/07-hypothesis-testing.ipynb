{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "dac6427e-b8df-46f9-bfd3-b24427a73993"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Data Science \n",
    "# Lecture 7: Statistical inference and hypothesis testing \n",
    "*COMP 5360 / MATH 4100, University of Utah, http://datasciencecourse.net/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In this lecture, we'll cover \n",
    "* Statistical inference\n",
    "* Central limit theorem\n",
    "* Hypothesis testing and the z-test\n",
    "* Confidence intervals\n",
    "* A/B testing\n",
    "\n",
    "Mandatory reading:\n",
    "+ [WIRED article on A/B testing](http://www.wired.com/2012/04/ff_abtesting/)\n",
    "\n",
    "Mandatory listening:\n",
    "+ [Planet Money Episode 677: The experiment experiment](https://www.npr.org/sections/money/2018/03/07/591213302/episode-677-the-experiment-experiment)\n",
    "+ [Planet Money Episode 669: A or B](https://www.npr.org/sections/money/2015/12/11/459412925/episode-669-a-or-b) \n",
    "\n",
    "Further reading: \n",
    "+ Jay L. Devore, Probability and Statistics for Engineering and the Sciences, 9th ed. Cengage Learning (2016) Ch. 8 and 9.\n",
    "+ R. Nuzzo, Scientific method: Statistical errors, Nature (2014) [link](https://doi.org/10.1038/506150a)\n",
    "+ J. Cohen, The Earth is Round (p<0.05), American Psychologist (1994) [link](https://doi.org/10.1037/0003-066x.49.12.997)\n",
    "\n",
    "\n",
    "For a more complete treatment, take Math 3070 (Applied Statistics I).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#imports and setup\n",
    "import pandas as pd\n",
    "\n",
    "import scipy as sc\n",
    "from scipy.stats import bernoulli\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t\n",
    "from scipy.stats import probplot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap of Lecture 4: Descriptive vs. Inferential Statistics \n",
    "\n",
    "*Descriptive statistics* quantitatively describes or summarizes features of a dataset. \n",
    "\n",
    "*Inferential statistics* attempts to learn about the population from which the data was sampled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap of Lecture 4:  discrete random variables\n",
    "\n",
    "*Discrete random variables* take discrete values with preassigned probabilities described by a probability mass function (PMF). If $X$ is the random variable and $f(k)$ is the PMF, we say \"the probability that $X$ takes value $k$ is given by $f(k)$\" and write\n",
    "$$\n",
    "\\textrm{Prob}(X=k) = f(k).\n",
    "$$\n",
    "\n",
    "### Bernoulli distribution\n",
    "A Bernoulli random variable can take the values $k=0$ or $1$ and has PMF\n",
    "$$\n",
    "f(k) = \\begin{cases} p & k=1 \\\\ 1-p & k = 0 \\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "Some facts about Bernoulli variables: \n",
    "* mean is $p$\n",
    "* variance is $p(1-p)$\n",
    "\n",
    "**Example:** The Bernoulli distribution with $p=0.5$ describes a 'fair' coin toss where 1 and 0  represent \"heads\" and \"tails\", respectively. If the coin is unfair, then we would have that $p\\neq 0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Binomial distribution\n",
    "\n",
    "A binomial r.v. takes values $k=0,1,\\ldots,n$, with a probability given by the PMF \n",
    "$$\n",
    "f(k) = \\binom{n}{k} p^k (1-p)^{n-k}.\n",
    "$$\n",
    "Here, $\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$ in the binomial coefficient that describes how many ways there are to choose a subset of $k$ elements, disregarding their order, from a set of $n$ elements.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n =10\n",
    "p = 0.5\n",
    "f = lambda k: binom.pmf(k, n=n,p=p)\n",
    "\n",
    "x = sc.arange(n+1);\n",
    "plt.plot(x, f(x),'*-')\n",
    "plt.title(\"The PMF for a binomial random variable\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"f(k)\")\n",
    "plt.xlim([0,n])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Some facts about the binomial distribution:\n",
    "- A binomial random variable is just the sum of $n$ Bernoulli random variables. You can think of it as summarizing the resutls of $n$ coin flips by just keeping track of the total number of heads.\n",
    "- The mean is  $np$\n",
    "- The variance is  $np(1âˆ’p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Poisson distribution\n",
    "You also saw the Poisson random variable in the homework, which is another example of a discrete random variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap of Lecture 4:  continuous random variables\n",
    "\n",
    "A *continuous random variable* can take any real value, but some numbers are more likely than others. The probability is given by the *probability density function (PDF)*, which is analogous to the PMF for discrete random variables. If f(x) is the PDF for the random variable $X$, then the probability that $X$ takes the value in the interval $[a,b]$ is given by \n",
    "$$\n",
    "\\textrm{Prob}(X\\in[a,b]) = \n",
    "\\int_a^b f(x) dx.\n",
    "$$\n",
    "This is just the area under the curve for this interval.\n",
    "\n",
    "### Example: Normal (Gaussian) distribution \n",
    "\n",
    "The *probability density function (PDF)* for a normal (Gaussian) random variable is\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sqrt{ 2 \\pi \\sigma^2 }}\n",
    "e^{ - \\frac{ (x - \\mu)^2 } {2 \\sigma^2} }.\n",
    "$$\n",
    "This is sometimes referred to as the 'bell curve'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "mu = 0 # mean\n",
    "sigma = 1 # standard deviation \n",
    "x = sc.arange(mu-4*sigma,mu+4*sigma,0.001);\n",
    "pdf = norm.pdf(x,loc=mu, scale=sigma)\n",
    "plt.title(\"The probability density function for a normal random variable\")\n",
    "plt.plot(x, pdf, linewidth=2, color='k')\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Some facts about the normal distribution:\n",
    "- The mean is $\\mu$\n",
    "- The variance is  $\\sigma^2$\n",
    "\n",
    "To compute the integral \n",
    "$$\n",
    "\\textrm{Prob}(X\\in[a,b]) = \n",
    "\\int_a^b f(x) dx,\n",
    "$$\n",
    "it is useful to define the *cumulative distribution function* (CDF)\n",
    "$$\n",
    "F(x) = \\int_{-\\infty}^x f(x) dx.\n",
    "$$\n",
    "Then we can write \n",
    "$$\n",
    "\\int_a^b f(x) dx =\n",
    "\\int_{-\\infty}^b f(x) dx  - \\int_{-\\infty}^a f(x) dx =\n",
    "F(b) - F(a).\n",
    "$$\n",
    "This is convenient because we know longer have to evaluate an integral! However, there isn't a nice way to write $F(x)$ for the normal distribution in terms of elementary functions. So we just think about $F(x)$ as a known function that we can easily compute using python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "mu = 0 # mean\n",
    "sigma = 1 # standard deviation \n",
    "x = sc.arange(mu-4*sigma,mu+4*sigma,0.001);\n",
    "cdf = norm.cdf(x,loc=mu, scale=sigma)\n",
    "plt.title(\"The cumulative density function for a normal random variable\")\n",
    "plt.plot(x, cdf, linewidth=2, color='k')\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"F(x)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Exercise \n",
    "Interpret the following in terms of normal random variables:\n",
    "- $\\int_{-\\infty}^1 f(x) dx = F(1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "norm.cdf(1, loc=mu, scale=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- $\\int_{-1}^1 f(x) dx = F(1) - F(-1)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "norm.cdf(1, loc=mu, scale=sigma) - norm.cdf(-1, loc=mu, scale=sigma) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "+ $\\int_{-\\infty}^\\infty f(x) dx = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "norm.cdf(sc.inf, loc=mu, scale=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "+ $\\int_1^1 f(x) dx = F(1) - F(1) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\n",
    "**Remark:** There are many other continuous random variables, but in this class we'll mostly only consider the normal random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Checking if a random variable is a normal random variable \n",
    "\n",
    "Given sample data, $x_1, x_2, x_3 \\ldots$, how do you know if the data came from a normal distribution? \n",
    "\n",
    "+ There is a visual check called the \"normal probability plot\". \n",
    "\n",
    "In a [normal probability plot](https://en.wikipedia.org/wiki/Normal_probability_plot), the sorted data are plotted vs. values selected to make the points look close to a straight line if the data are approximately normally distributed. Deviations from a straight line suggest departures from normality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_size = 200\n",
    "\n",
    "x = norm.rvs(loc=0, scale=1, size=samp_size)\n",
    "probplot(x, plot=plt)\n",
    "plt.title(\"Normal probability plot\")\n",
    "plt.xlabel(\"Normal quantiles\")\n",
    "plt.ylabel(\"Ordered values\")\n",
    "plt.show()\n",
    "\n",
    "x = t.rvs(df=3,size=samp_size)\n",
    "probplot(x, plot=plt)\n",
    "plt.title(\"Normal probability plot\")\n",
    "plt.xlabel(\"Normal quantiles\")\n",
    "plt.ylabel(\"Ordered values\")\n",
    "plt.show()\n",
    "\n",
    "from scipy.stats import laplace\n",
    "x = laplace.rvs(size=samp_size)\n",
    "probplot(x, plot=plt)\n",
    "plt.title(\"Normal probability plot\")\n",
    "plt.xlabel(\"Normal quantiles\")\n",
    "plt.ylabel(\"Ordered values\")\n",
    "plt.show()\n",
    "\n",
    "from scipy.stats import gamma\n",
    "x = gamma.rvs(a=2,size=samp_size)\n",
    "probplot(x, plot=plt)\n",
    "plt.title(\"Normal probability plot\")\n",
    "plt.xlabel(\"Normal quantiles\")\n",
    "plt.ylabel(\"Ordered values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hypothesis testing\n",
    "\n",
    "Suppose we have a coin and we want to determine whether or not it is 'fair'. We could flip it many, many times and count how many heads we obtain. If the fraction of heads is approximately $0.5$, we might argue that the coin is fair. \n",
    "\n",
    "This is an example of statistical inference. We are trying to determine something about the coin from samples of coin flips. \n",
    "\n",
    "Let's say we flip a coin $n=1000$ times. If the coin is fair, the outcome is described by the Binomial distribution with $p=0.5$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "f = lambda k: binom.pmf(k, n=1000,p=0.5)\n",
    "\n",
    "x = sc.arange(1001);\n",
    "plt.plot(x, f(x),'*-')\n",
    "plt.plot(545,f(545),'o')\n",
    "plt.title(\"The probability mass function for a Binomial random variable\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"f(k)\")\n",
    "plt.xlim([0,1001])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Suppose that in our experiment, we saw $545$ heads. The probability of this occurring is \n",
    "f(k = 545):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "binom.pmf(545, n=1000,p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In hypothesis testing, the more important question is: what is the probability of seeing a value as extreme or more extreme than the value that we observed? \n",
    "\n",
    "We might say that any result $\\geq 545$ is 'as or more extreme'.\n",
    "\n",
    "So the probability of seeing as extreme of an outcome is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "s = sum(binom.pmf(sc.arange(545,1001),n=1000,p=0.5))\n",
    "print(s)\n",
    "print(1-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Actually, seeing any result $\\leq 455$ would be 'as or more extreme' too. Why?\n",
    "\n",
    "So the probability of seeing as extreme of an outcome is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = sum(binom.pmf(sc.arange(0,456),n=1000,p=0.5)) # why 456? \n",
    "s2 = sum(binom.pmf(sc.arange(545,1001),n=1000,p=0.5))\n",
    "print(s1)\n",
    "print(s2)\n",
    "s = s1 + s2\n",
    "\n",
    "print(s)\n",
    "print(1-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So the probability of seeing so many heads or so many tails is just $0.49\\%$. So it is very unlikely that if the coin were fair, we would see this result! Maybe so unlikely that we would declare that the coin is unfair? This is the idea behind **hypothesis testing**. \n",
    "\n",
    "**Note**: I didn't say that \"it is unlikely that the coin is fair\". But rather: \"if the coin were fair, it would be unlikely to see this result\". \n",
    "\n",
    "In *hypothesis testing*, we make a null hypothesis, written $H_0$. In this case, the null hypothesis is\n",
    "$$\n",
    "H_0: \\text{the coin is fair, i.e., $p=0.5$}.\n",
    "$$\n",
    "The alternative hypothesis, $H_a$, is typically the hypothesis that the researcher wants to validate. In this case, $H_a$ is that the coin is unfair, i.e., $p\\neq 0.5$. \n",
    "\n",
    "We also choose a *significance level* for the test, $\\alpha$, traditionally $1\\%$ or $5\\%$. \n",
    "In this case, let's choose a significance level of $\\alpha = 1\\%$. \n",
    "\n",
    "We then perform an experiment. In this case, we flip the coin 1000 times and count the number of heads (in this case 545). \n",
    "\n",
    "Finally, assuming the null hypothesis is true, we compute how likely it is to see a number that is at least as far from the expected value as the number obtained. In our case, this is $0.49\\%$. The is called the *p-value*. Since $p=0.49\\%$ is smaller than the chosen significance level, $\\alpha = 1\\%$, we reject the null hypothesis and declare the coin to be unfair.  \n",
    "\n",
    "Some comments about the p-value:\n",
    "1. A p-value is a probability calculated assuming that $H_0$ is true. \n",
    "+ The smaller the p-value, the stronger the evidence against $H_0$.\n",
    "+ **Warning:** A p-value is not the probability that the null hypothesis is true or false. It is the probability that an erroneous conclusion is reached assuming the null hypothesis to be true. In this example, it is the probability that the coin actually is fair and we just happened to see an outcome at least as extreme as 545 heads.\n",
    "\n",
    "To avoid computing sums (as above) and to 'normalize' the above procedure, it is useful to introduce the *Central Limit Thoerem*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Central Limit Theorem \n",
    "\n",
    "One of the reasons that the normal distribution is **so important** is the following theorem. \n",
    "\n",
    "**Central Limit Theorem.** Let $\\{X_1,\\ldots, X_n\\}$ be a sample of $n$ random variables chosen identically and independently from a distribution with mean $\\mu$ and finite variance $\\sigma^2$. If $n$ is 'large', then \n",
    "- the sum of the variables $\\sum_{i=1}^n X_i$ is also a random variable and is approximately **normally** distributed with mean $n\\mu$ and variance $n\\sigma^2$ and\n",
    "- the mean of the variables $\\frac{1}{n}\\sum_{i=1}^n X_i$ is also a random variable and is approximately **normally** distributed with mean $\\mu$ and variance $\\frac{\\sigma^2}{n}$.\n",
    "\n",
    "How can we use the central limit theorem (CLT)? \n",
    "\n",
    "Recall that a binomial random variable is the sum of $n$ Bernoulli random variables. So the CLT tells us that if $n$ is large, binomial random variables will be distributed approximately normally. That is, if we flip a coin many times, the number of heads that we're likely to see is described by a normal distribution. This provides a different (easier) way to answer the question: How unlikely is it to flip a fair coin 1000 times and see 545 heads? \n",
    "\n",
    "Suppose we flip a fair ($p=0.5$) coin 1000 times. \n",
    "\n",
    "*Question:* How many heads do we expect to see? \n",
    "\n",
    "The CLT says that the number of heads (= sum of Bernoulli r.v. = binomial r.v.) is approximately normally distributed with mean \n",
    "$$ \n",
    "n\\mu = np = 1000*0.5 = 500 \n",
    "$$\n",
    "and variance \n",
    "$$ \n",
    "n \\sigma^2 = np(1-p) = 1000*0.5*0.5 = 250. \n",
    "$$\n",
    "\n",
    "Let's do an experiment to see how good the CLT is for Bernoulli random variables. We'll call flipping a fair coin n=1,000 times and counting the number of heads a \"simulation\". Recall that the outcome is precisely a binomial random variable with n=1,000 and p = 0.5. We'll do 10,000 simulations and then compare the histogram of the binomial random variables and the normal distribution predicted by the CLT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "p = 0.5\n",
    "bin_vars = binom.rvs(n=n,p=p,size=10000)\n",
    "\n",
    "plt.hist(bin_vars, bins='auto',density=True)\n",
    "\n",
    "mu = n*p \n",
    "sigma = sc.sqrt(n*p*(1-p))\n",
    "x = sc.arange(mu-4*sigma,mu+4*sigma,0.1);\n",
    "pdf = norm.pdf(x, loc=mu, scale=sigma)\n",
    "plt.plot(x, pdf, linewidth=2, color='k')\n",
    "plt.title(\"A comparison between the histogram of binomial random \\n variables and the normal distribution predicted by the CLT\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "probplot(bin_vars, plot=plt)\n",
    "plt.title(\"Normal probability plot\")\n",
    "plt.xlabel(\"Normal quantiles\")\n",
    "plt.ylabel(\"Ordered values\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So what is the likelihood of flipping a coin 1000 times and seeing an event less extreme than 545 heads? \n",
    "\n",
    "The CLT tells us that this is approximately \n",
    "$$\n",
    "\\int_{455}^{545} f(x) dx = F(545) - F(455).\n",
    "$$\n",
    "\n",
    "This is something that we can easily evaluate using the cumulative distribution function (CDF). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "p = 0.5\n",
    "mu = n*p\n",
    "sigma = sc.sqrt(n*p*(1-p))\n",
    "print(norm.cdf(545, loc=mu, scale=sigma) - norm.cdf(455, loc=mu, scale=sigma)) \n",
    "\n",
    "# a plot illustrating the integral \n",
    "x = sc.arange(mu-4*sigma,mu+4*sigma,0.001);\n",
    "plt.plot(x, norm.pdf(x, loc=mu, scale=sigma), linewidth=2, color='k')\n",
    "x2 = sc.arange(455,545,0.001)\n",
    "plt.fill_between(x2, y1= norm.pdf(x2,loc=mu, scale=sigma), facecolor='red', alpha=0.5)\n",
    "plt.xlim([mu-4*sigma,mu+4*sigma])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So again, we see that $99.5\\%$ of the time, we would see an event less extreme than 545 heads.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: \"Freshman 15\": Fact or Fiction\n",
    "\n",
    "This example was taken from Devore, pp.314-315. \n",
    "\n",
    "\"A common belief among the lay public is that body weight increases after entry into college, and the phrase 'freshman 15' has been coined to describe the 15 pounds that students presumably gain over their freshman year.\"\n",
    "\n",
    "Let $\\mu$ denote the true average weight gain in the first year of college. We take the null hypothesis to be\n",
    "$$\n",
    "H_0: \\mu \\geq 15\n",
    "$$\n",
    "so that the alternative hypothesis is that the average weight gain in the first year of college is less than 15 lbs ($H_a:  \\mu < 15$). \n",
    "\n",
    "We set a significance level of, say, $\\alpha = 1\\%$. \n",
    "\n",
    "We suppose a random sample of $n$ students is selected, their weights (before and after the first year of college) are measured, and the sample mean $\\bar{x}$ and sample standard deviation $s$ are computed. An article in the journal Obesity (2006) cites that for a sample of $n=137$ students, the sample mean weight gain was $\\bar{x}=2.42$ lb and with a sample standard deviation of $s=5.72$ lb. \n",
    "\n",
    "Assuming $H_0$ to be true, how unlikely is it that we would observe such a small value ($\\bar{x}=2.42$)?  \n",
    "\n",
    "The CLT says that \n",
    "+ the mean of the variables $\\frac{1}{n}\\sum_{i=1}^n X_i$ is a random variable and is approximately **normally** distributed with mean $\\mu$ and variance $\\frac{\\sigma^2}{n}$.\n",
    "\n",
    "\n",
    "We take a normal distribution with mean given by the null value ($\\mu = 15$) and variance given by $s^2/n = (5.72)^2/137=0.2388$. \n",
    "\n",
    "The $p$-value is then computed as the probability that $\\bar{x}< 2.42$, \n",
    "$$\n",
    "P(\\bar{x}< 2.42) = \\int_{-\\infty}^{2.42} f(x) dx = F(2.42).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "mu = 15\n",
    "sigma = sc.sqrt(5.72**2/137)\n",
    "print('p:', norm.cdf(2.42, loc=mu, scale=sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The p-value is practically zero, much less than the significance level! The data very strongly contradicts the null hypothesis. We reject the null hypothesis, $H_0$, and conclude that the 'freshman 15' is fiction! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Zinc in Batteries\n",
    "\n",
    "This example was taken from Devore, pp.317. \n",
    "\n",
    "A random sample of $n=51$ Panasonic AAA batteries gave a sample mean zinc mass of $\\bar{X}=2.06$ grams and a sample standard deviation of $S=0.141$ grams. \n",
    "\n",
    "**Question**: Does this data provide compelling evidence for concluding that the population mean zinc mass exceeds 2.0 grams, as reported by the company? \n",
    "\n",
    "Let $\\mu$ denote the true average zinc mass of such batteries. We take the null hypothesis to be\n",
    "$$\n",
    "H_0: \\mu \\leq 2.0\n",
    "$$\n",
    "and that the alternative hypothesis is\n",
    "$$\n",
    "H_a:  \\mu > 2.0.\n",
    "$$\n",
    "\n",
    "We set a significance level of, say, $\\alpha = 1\\%$. \n",
    "\n",
    "According to the CLT, the sample mean $\\bar{X}$ has approximately a normal distribution with mean $\\mu = 2.0$ (Assuming $H_0$) and standard deviation $S/\\sqrt{n}$. We could proceed as previously but it is more standard to normalize the variable.  \n",
    "\n",
    "To proceed, we conduct a **z-test**, which is the same as we did in the previous example, except now we use the normalized $Z$-statistic, \n",
    "$$\n",
    "Z = \\frac{\\bar{X} - 2.0}{S/\\sqrt{n}}. \n",
    "$$\n",
    "The $Z$-statistic is distributed according to the \"standard\" normal distribution with mean $\\mu=0$ and standard deviation $\\sigma = 1$.\n",
    "\n",
    "Assuming $H_0$ to be true, how unlikely is it that we would observe such a large value ($\\bar{X}=2.06$)?\n",
    "$$\n",
    "P-\\textrm{value} = P (\\bar{X} \\geq 2.06) = P (Z\\geq 3.04) = \\int_{3.04}^\\infty f(x) dx = 1 - F(3.04). = .0012.  \n",
    "$$\n",
    "Because the $P$-value $= .0012 \\leq .01 = \\alpha$, the null hypothesis should be rejected at the chosen significance level. We conclude that the average zinc mass in the batteries exceeds 2.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1 - norm.cdf(2.06, loc=2.0, scale = 0.141/sc.sqrt(51)))\n",
    "\n",
    "z = (2.06 - 2.0) / (0.141/sc.sqrt(51))\n",
    "print(1 - norm.cdf(z, loc=0, scale=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary of hypothesis testing and the z-test\n",
    "1. Identify the parameter of interest and describe it in the context of the problem. \n",
    "+ Determine the null and alternative hypotheses.\n",
    "+ Choose a significance level $\\alpha$. \n",
    "+ Find the formula for the computed value of the test statistic, *e.g.*, \n",
    "$Z = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}}$ (use the CLT).\n",
    "+ Using the sampled data, compute the $P$-value, *e.g.*, $F(z)$\n",
    "+ Compare the significance level to the $P$-value to decide whether or not the null hypothesis should be rejected and state the conclusion in the problem context. Report the $P$-value! \n",
    "\n",
    "\n",
    "\n",
    "### One- and two- sided hypothesis testing:\n",
    "\n",
    "Depending on the null and alternative hypothesis, the $P$-value will be different integrals of the 'bell curve'. This is called [one- and two- sided hypothesis testing](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests).\n",
    "\n",
    "<img src=\"determinePvals.png\" width=\"600\">\n",
    "$\\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad$ \n",
    "source: Devore, pp.329\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What to do for smaller sample sizes? Student's t-test\n",
    "\n",
    "When $n$ is small, the Central Limit Theorem can no longer be used. In this case, if the samples are drawn from an approximately normal distribution, then the correct distribution to use is called the [Student's t distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution) with $\\nu = n-1$ degrees of freedom. The probability density function (pdf) for the student's t distribution is not pretty (Google it!) but it is built into scipy, so we can compare the student's t-test to the normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# there is some trouble with this package for some python versions\n",
    "# if it doesn't work, don't worry about it\n",
    "from ipywidgets import interact \n",
    "\n",
    "samp_mean = 0\n",
    "samp_std_dev = 1\n",
    "\n",
    "x = sc.linspace(samp_mean-4*samp_std_dev,samp_mean+4*samp_std_dev,1000);\n",
    "def compare_distributions(sample_size):\n",
    "    pdf1 = norm.pdf(x, loc=samp_mean, scale=samp_std_dev/sc.sqrt(sample_size))\n",
    "    pdf2 = t.pdf(x,df=sample_size-1,loc=samp_mean, scale=samp_std_dev/sc.sqrt(sample_size))\n",
    "    plt.plot(x, pdf1, linewidth=2, color='k',label='normal distribution pdf')\n",
    "    plt.plot(x, pdf2, linewidth=2, color='r',label='t distribution pdf')\n",
    "    plt.xlim(x.min(),x.max())\n",
    "    plt.ylim(0,2)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "interact(compare_distributions,sample_size=(2,20,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The student's t distribution has \"heavier tails\" than the normal distribution. For a sample size greater than $\\approx 20$, the normality assumption is generally accepted as reasonable. \n",
    "\n",
    "In the previous example, $n=51$, which is large enough to assume normality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Types of error in hypothesis testing \n",
    "\n",
    "In hypothesis testing, there are [two types of errors](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors). \n",
    "+ A **type I error** is the incorrect rejection of a true null hypothesis (a \"false positive\"). \n",
    "+ A **type II error** is incorrectly accepting a false null hypothesis (a \"false negative\"). \n",
    "\n",
    "Depending on the application, one type of error can be more consequential than the other. \n",
    "\n",
    "![](InferenceErrors.png)\n",
    "$\\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad$ \n",
    "source: [wikipedia](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors)\n",
    "\n",
    "The probability of making a type I (false positive) error is the significance level $\\alpha$. \n",
    "\n",
    "The probability of making a type II (false negative) error is more difficult to calculate. \n",
    "\n",
    "**Examples**\n",
    "\n",
    "**(1)** In drug testing, we take the null hypothesis (H0): \"This drug has no effect on the disease.\" A type I error detects an effect (the drug cures the disease) that is not present. A type II error fails to detect an effect (the drug cures the disease) that is present. \n",
    "\n",
    "**(2)** In a trial, we take the null hypothesis (H0): \"This man is innocent.\" A type I error convicts an innocent person. A type II error lets a guilty person go free. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## P hacking\n",
    "\n",
    "Recall that the p-value measures how extreme the observation is and is compared to the significance level. Some comments about the p-value:\n",
    "1. A p-value is a probability calculated assuming that $H_0$ is true. \n",
    "+ The smaller the p-value, the stronger the evidence against $H_0$.\n",
    "+ A p-value is not the probability that the null hypothesis is true or false. It is the probability that an erroneous conclusion is reached.\n",
    "\n",
    "Recently the *misuse* of hypothesis testing (p-values) has raised considerable controversy. Basically, if you do enough hypothesis tests, eventually you'll have a Type I (false positive) error. This is sometimes referred to as [Data dredging](https://en.wikipedia.org/wiki/Data_dredging). This is a real problem in a world with tons of data in which it is easy to do many, many hypothesis tests automatically. One method to avoid this is called *cross-validation*, which we'll discuss later. \n",
    "\n",
    "You can read more about 'P hacking' here:\n",
    "\n",
    "- R. Nuzzo, Scientific method: Statistical errors, Nature (2014) [link](https://doi.org/10.1038/506150a)\n",
    "\n",
    "- J. Cohen, The Earth is Round (p<0.05), American Psychologist (1994) [link](https://doi.org/10.1037/0003-066x.49.12.997)\n",
    "\n",
    "- [Planet Money Episode 677: The experiment experiment](https://www.npr.org/sections/money/2018/03/07/591213302/episode-677-the-experiment-experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confidence intervals\n",
    "\n",
    "A [confidence interval](https://en.wikipedia.org/wiki/Confidence_interval) is an interval estimate for an unknown population parameter. For example, we might use collected data to give an interval estimate for a population mean. \n",
    "\n",
    "### Example: Ergonomic keyboards \n",
    "\n",
    "This example was taken from Devore, pp.277.\n",
    "\n",
    "*Question*: A study is conducted to estimate the preferred height for an experimental keyboard with large forearm-wrist support. A sample of $n=31$ trained typists was selected, and the preferred keyboard height was determined for each typist. The resulting sample average preferred height was $\\bar{X} = 80.0$ cm. Assuming that the preferred height is normally distributed with $\\sigma = 2.0$ cm, obtain a confidence interval for $\\mu$, the true average preferred height for the population of all typists. \n",
    "\n",
    "The CLT tells us that the sample mean $\\bar X$ is normally distributed with expected value $\\mu$ and standard deviation $\\sigma / \\sqrt n$. Standardizing $\\bar X$ by subtracting the expected value and dividing by the standard deviation yields the standard normal variable \n",
    "$$\n",
    "Z = \\frac{\\bar X - \\mu}{\\sigma / \\sqrt n}.\n",
    "$$\n",
    "\n",
    "Since $Z$ is a standard normal variable, and the integral under the standard normal curve between -1.96 and 1.96 is 0.95, we have that \n",
    "$$\n",
    "P( -1.96 < Z < 1.96) = 0.95.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "norm.cdf(1.96) - norm.cdf(-1.96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's manipulate the inequalities inside the parenthesis:\n",
    "$$\n",
    "-1.96 \\ < \\ \\frac{\\bar X - \\mu}{\\sigma / \\sqrt n} \\ < \\ 1.96.\n",
    "$$\n",
    "This is equivalent to \n",
    "$$\n",
    "\\bar X -1.96 \\frac{\\sigma}{\\sqrt n} \\ < \\ \\mu \\ < \\ \\bar X + 1.96\\frac{\\sigma}{\\sqrt n}, \n",
    "$$\n",
    "which we think of as the interval \n",
    "$$\n",
    "I = \\left( \\bar X -1.96 \\frac{\\sigma}{\\sqrt n}, \\  \\bar X +1.96 \\frac{\\sigma}{\\sqrt n} \\right) \n",
    "$$\n",
    "containing the population mean $\\mu$. \n",
    "The interval can be computed using the sampled data, $I = (79.3, 80.7)$. \n",
    "All together we have \n",
    "$$\n",
    "P\\left( I \\textrm{ contains } \\mu  \\right) = 0.95.\n",
    "$$\n",
    "We say that $I = (79.3, 80.7)$ is the 95% confidence interval for the averaged preferred height. \n",
    "\n",
    "**Comments:**\n",
    "+ The 95% confidence interval *does not* mean that with probability 95%, the true value of $\\mu$ lies within the interval. \n",
    "+ A 95% confidence interval means that if we were to repeat the same experiment many times, and compute the confidence interval using the same formula, 95% of the time it would contain the true value of $\\mu$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A/B testing\n",
    "*A/B testing* is a method of comparing two or more versions of an advertisement, webpage, app, etc. We set up an experiment where the variants are shown to users at random and statistical analysis is used to determine which is best. AB testing is the *de facto* test for many business decisions.  \n",
    "\n",
    "**Example.** A/B testing was extensively used by President Obama during his 2008 and 2012 campaigns to  develop \n",
    "* optimized fund-raising strategies,  \n",
    "* get-out-the-vote programs that would be most beneficial, and \n",
    "* target ads to the most susceptible audiences. \n",
    "\n",
    "Learn more here:\n",
    "[Wired story on A/B testing](http://www.wired.com/2012/04/ff_abtesting/)\n",
    "and \n",
    "[Planet Money Episode 669: A or B](https://www.npr.org/sections/money/2015/12/11/459412925/episode-669-a-or-b)\n",
    "\n",
    "**Example.** Suppose your company is developing an advertisement. The art department develops two internet ads: \"Ad A\" and \"Ad B\". Your job is to figure out which is better. \n",
    "\n",
    "You decide to do an experiment: You use Google ads to randomly show 1000 internet users Ad A and 1000 internet users Ad B. \n",
    "\n",
    "It turns out that 500 Ad A viewers click on the ad while 550 Ad B viewers click on the ad? Obviously Ad B did better, but is the difference \"significant\" enough to say that Ad B is better? Or perhaps Ad B just got lucky in this test? \n",
    "\n",
    "In homework 4, youâ€™ll answer this question. More generally, this is a question about the difference between population proportions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical inference for a difference between population proportions\n",
    "We consider comparing the population proportions of two different populations. \n",
    "\n",
    "We make the following definitions:\n",
    "- $N_A$ is the number of surveyed people from population $A$  \n",
    "- $n_A$ is the number of successes from population $A$\n",
    "- $p_A = n_A/N_A$ is the proportion of successes from population $A$\n",
    "\n",
    "Similarly, we define \n",
    "- $N_B$ is the number of surveyed people from population $B$  \n",
    "- $n_B$ is the number of successes from population $B$\n",
    "- $p_B = n_B/N_B$ is the proportion of successes from population $B$\n",
    "\n",
    "We make the null hypothesis:\n",
    "$$\n",
    "H_0\\colon \\text{$p_A$ and $p_B$ are the same, that is, } p_A - p_B = 0.\n",
    "$$\n",
    "That is, the proportion of successes in the two populations is the same. \n",
    "\n",
    "We'll take it as a fact (see Devore Ch. 9.4 or Math 3070) that: \n",
    "- $n_A/N_A$ is approximately a normal random variable with mean $p_A$ and variance $\\sigma_A^2 = p_A(1-p_A)/N_A$ \n",
    "- $n_B/N_B$ is approximately a normal random variable with mean $p_B$ and variance $\\sigma_B^2 = p_B(1-p_B)/N_B$\n",
    "- $n_A/N_A - n_B/N_B$ is approximately a normal random variable with mean $\\mu = 0$ and variance $\\sigma^2 = \\sigma_A^2 + \\sigma_B^2$. \n",
    "- The test statistic called the *two-proportion z-value* \n",
    "$$\n",
    "Z = \\frac{p_A - p_B}{\\sqrt{\\hat{p} \\hat{q} \\left( \\frac{1}{N_A} + \\frac{1}{N_B} \\right)}}.\n",
    "$$\n",
    "is approximately  distributed according to the standard normal distribution when $H_0$ is true. Here $\\hat{p} = \\frac{N_A}{N_A + N_B}p_A + \\frac{N_B}{N_A + N_B}p_B$ and $\\hat{q} = 1-\\hat{p}$. \n",
    "\n",
    "From the data, we estimate the mean, $\\mu$, to be  $p_A - p_B$. \n",
    "\n",
    "## Example: 1954 Salk polio-vaccine experiment\n",
    "\n",
    "In 1954, polio was widespread and a new vaccine of unknown efficacy was introduced. To test the efficacy, in a double-blind study, two groups of children were give injections: one contained the vaccine and the other contained a placebo. \n",
    "\n",
    "Let $p_A$ and $p_B$ be the proportions of the children, having received the placebo and vaccine injections, respectively, to contract polio. We formulate the null hypothesis that \n",
    "$$\n",
    "H_0\\colon p_A - p_B \\leq 0,\n",
    "$$\n",
    "that is, the vaccine is not effective.\n",
    "The alternative hypothesis is that \n",
    "$$\n",
    "H_a\\colon p_A - p_B >0, \n",
    "$$\n",
    "that is, a vaccinated child is less likely to contract polio than a child receiving the placebo.\n",
    "\n",
    "We choose a significance level of $\\alpha = 0.01$. \n",
    "\n",
    "An experiment was conducted with the following results: \n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\text{Placebo:} \\quad N_A = 201,229, \\quad n_A = 110 \\\\\n",
    "&\\text{Vaccine:} \\quad N_B = 200,745, \\quad n_B = 33.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "nA = 110\n",
    "NA = 201229\n",
    "pA = nA/NA\n",
    "muA = pA\n",
    "sigmaA = sc.sqrt(pA*(1-pA)/NA)\n",
    "\n",
    "nB = 33\n",
    "NB = 200745\n",
    "pB = nB/NB\n",
    "muB = pB\n",
    "sigmaB = sc.sqrt(pB*(1-pB)/NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Now we perform the hypothesis test and see what the probability of the outcome is under the assumption of the null hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "phat = NA*pA/(NA+NB) + NB*pB/(NA+NB)\n",
    "qhat = 1-phat\n",
    "\n",
    "z = (pA - pB)/sc.sqrt(phat*qhat*(1/NA + 1/NB)) \n",
    "print(z)\n",
    "\n",
    "p_value = 1-norm.cdf(z)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The probability that an erroneous conclusion is reached, under the assumption of the null hypothesis, is $6.6\\times10^{-11}$, way less than the significance level, $\\alpha$. We reject the null hypothesis and declare that the vaccine is more effective than a placebo! "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nbpresent": {
   "slides": {
    "006f01ca-e160-4faa-ad02-2f873362ca99": {
     "id": "006f01ca-e160-4faa-ad02-2f873362ca99",
     "prev": "e60ea09b-1474-49b0-9ea6-2e803b335693",
     "regions": {
      "88222835-28de-4a0f-895e-303024baf060": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e6a51e7a-d63e-4187-8899-bfbf03f8a4b6",
        "part": "whole"
       },
       "id": "88222835-28de-4a0f-895e-303024baf060"
      }
     }
    },
    "2ba6955d-8be2-4ce3-ae98-f3b3695e4832": {
     "id": "2ba6955d-8be2-4ce3-ae98-f3b3695e4832",
     "prev": "35a7a5a6-f0c3-4b68-9579-e5840160a87d",
     "regions": {
      "63b4b5f3-c348-418c-aabf-932d5fdbcc1c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "883076a7-1c6e-492f-b9d2-0b8550b5c31f",
        "part": "whole"
       },
       "id": "63b4b5f3-c348-418c-aabf-932d5fdbcc1c"
      }
     }
    },
    "2d5e1e8f-2e26-415e-8d8d-9229f2dc1244": {
     "id": "2d5e1e8f-2e26-415e-8d8d-9229f2dc1244",
     "prev": "9ba8c8c8-59a7-4776-84cb-084e5b0a2317",
     "regions": {
      "44582fec-116b-475d-9793-ad29580b7fc2": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4992f285-654f-485e-81ef-8a6ae18cad34",
        "part": "whole"
       },
       "id": "44582fec-116b-475d-9793-ad29580b7fc2"
      }
     }
    },
    "35a7a5a6-f0c3-4b68-9579-e5840160a87d": {
     "id": "35a7a5a6-f0c3-4b68-9579-e5840160a87d",
     "prev": "c7291188-b014-4fcb-83bc-f1ea035ee4c9",
     "regions": {
      "cbc80f26-e933-4d90-9dfd-e55a3dc339ba": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "558af430-f4c0-4be9-b1ef-afce5fccd0fa",
        "part": "whole"
       },
       "id": "cbc80f26-e933-4d90-9dfd-e55a3dc339ba"
      }
     }
    },
    "3ecd0fe6-e75f-4362-a6e7-e5273e12058e": {
     "id": "3ecd0fe6-e75f-4362-a6e7-e5273e12058e",
     "prev": "2d5e1e8f-2e26-415e-8d8d-9229f2dc1244",
     "regions": {
      "eac20970-b45c-4073-a596-cdb2a974fe23": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "de60c848-d1fb-478d-a736-0ebe21762a24",
        "part": "whole"
       },
       "id": "eac20970-b45c-4073-a596-cdb2a974fe23"
      }
     }
    },
    "4e939c85-e2b3-48b3-b2df-389bc0ca7dd0": {
     "id": "4e939c85-e2b3-48b3-b2df-389bc0ca7dd0",
     "prev": "9807c9b8-54cd-4a78-b50d-1a6e9f7ff066",
     "regions": {
      "ddc97209-2f2f-409d-953c-a9a83dec6738": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "674ee724-0165-40c5-9296-83db8305fa4c",
        "part": "whole"
       },
       "id": "ddc97209-2f2f-409d-953c-a9a83dec6738"
      }
     }
    },
    "95bf00f9-fc2a-4478-bd48-fb66078e061f": {
     "id": "95bf00f9-fc2a-4478-bd48-fb66078e061f",
     "prev": "b9fa7815-a205-4ea6-9076-1289b96670cf",
     "regions": {
      "dd7aef1b-3f05-47a5-bc5f-274809d2c21d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "61e1167e-99ef-4b5d-b717-07a46077a091",
        "part": "whole"
       },
       "id": "dd7aef1b-3f05-47a5-bc5f-274809d2c21d"
      }
     }
    },
    "966d5c12-49ef-4129-aecb-b183804ecd19": {
     "id": "966d5c12-49ef-4129-aecb-b183804ecd19",
     "prev": "3ecd0fe6-e75f-4362-a6e7-e5273e12058e",
     "regions": {
      "ff0704a2-f662-4a03-9874-5613f4634956": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a6fd92a3-b57e-45c5-b216-f9f475baf8ce",
        "part": "whole"
       },
       "id": "ff0704a2-f662-4a03-9874-5613f4634956"
      }
     }
    },
    "9807c9b8-54cd-4a78-b50d-1a6e9f7ff066": {
     "id": "9807c9b8-54cd-4a78-b50d-1a6e9f7ff066",
     "prev": "966d5c12-49ef-4129-aecb-b183804ecd19",
     "regions": {
      "9e037b47-3fb5-4a60-b69c-ad3b282807a1": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b79fa570-8c08-4820-a035-2a00bfae1a9b",
        "part": "whole"
       },
       "id": "9e037b47-3fb5-4a60-b69c-ad3b282807a1"
      }
     }
    },
    "9ba8c8c8-59a7-4776-84cb-084e5b0a2317": {
     "id": "9ba8c8c8-59a7-4776-84cb-084e5b0a2317",
     "prev": "9e2b6ffd-bec2-4027-93e8-64b63e770378",
     "regions": {
      "45bb0df9-937a-48a6-882b-346a1253250c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "be5bedf1-b9ed-4caa-bc3e-6c390df97946",
        "part": "whole"
       },
       "id": "45bb0df9-937a-48a6-882b-346a1253250c"
      }
     }
    },
    "9e2b6ffd-bec2-4027-93e8-64b63e770378": {
     "id": "9e2b6ffd-bec2-4027-93e8-64b63e770378",
     "prev": "e9d31a55-0862-44ec-bd48-d74167655985",
     "regions": {
      "7a7c6996-8117-42ce-8093-318b84bd052b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "95b34ac1-b36d-492d-84f9-adafb2d57ace",
        "part": "whole"
       },
       "id": "7a7c6996-8117-42ce-8093-318b84bd052b"
      }
     }
    },
    "ae354c9e-1384-4f31-8e03-5c96f3988bf4": {
     "id": "ae354c9e-1384-4f31-8e03-5c96f3988bf4",
     "prev": null,
     "regions": {
      "9e57ef10-c941-41de-93da-812357c7ec21": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "dac6427e-b8df-46f9-bfd3-b24427a73993",
        "part": "whole"
       },
       "id": "9e57ef10-c941-41de-93da-812357c7ec21"
      }
     }
    },
    "b9fa7815-a205-4ea6-9076-1289b96670cf": {
     "id": "b9fa7815-a205-4ea6-9076-1289b96670cf",
     "prev": "ae354c9e-1384-4f31-8e03-5c96f3988bf4",
     "regions": {
      "cc19ec36-3caa-4666-86e7-2bd1d9cb03b8": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c7392535-4666-41a5-a68a-7306dccd6cd8",
        "part": "whole"
       },
       "id": "cc19ec36-3caa-4666-86e7-2bd1d9cb03b8"
      }
     }
    },
    "c7291188-b014-4fcb-83bc-f1ea035ee4c9": {
     "id": "c7291188-b014-4fcb-83bc-f1ea035ee4c9",
     "prev": "006f01ca-e160-4faa-ad02-2f873362ca99",
     "regions": {
      "3fa8900b-1ee2-4625-8e0b-a8a52d95390d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a912604c-786a-448e-a908-397f28b46a13",
        "part": "whole"
       },
       "id": "3fa8900b-1ee2-4625-8e0b-a8a52d95390d"
      }
     }
    },
    "e60ea09b-1474-49b0-9ea6-2e803b335693": {
     "id": "e60ea09b-1474-49b0-9ea6-2e803b335693",
     "prev": "4e939c85-e2b3-48b3-b2df-389bc0ca7dd0",
     "regions": {
      "3df2ec23-ba8a-4b76-b6af-2a4aa219da46": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "06d04c6d-90a4-441d-9d6e-4f719490e12e",
        "part": "whole"
       },
       "id": "3df2ec23-ba8a-4b76-b6af-2a4aa219da46"
      }
     }
    },
    "e9d31a55-0862-44ec-bd48-d74167655985": {
     "id": "e9d31a55-0862-44ec-bd48-d74167655985",
     "prev": "95bf00f9-fc2a-4478-bd48-fb66078e061f",
     "regions": {
      "cc6bd695-e238-4250-8822-ffea3f82f544": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "86c3f014-9535-48f0-95a2-df74d16eaa69",
        "part": "whole"
       },
       "id": "cc6bd695-e238-4250-8822-ffea3f82f544"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
